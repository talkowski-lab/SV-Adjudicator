# 01. Algorithm integration

This workflow integrates all variant calls in a batch of samples on a per-algorithm basis.

Frequently, samples are called jointly in a small group, which is a subset of a larger batch of sequencing libraries. To accomodate this paradigm, the user specifies a sample key, indicating which group and batch each sample belongs to, e.g.

```
sample       group   batch
fam1.fa      fam1   Pilot
fam1.mo      fam1   Pilot
fam1.p1      fam1   Pilot
fam1.s1      fam1   Pilot
fam2.fa      fam2   Phase1
fam2.mo      fam2   Phase1
fam2.p1      fam2   Phase1
fam2.s1      fam2   Phase1
```

The workflow expects a PE/SR VCF for each group, and a depth bed for each batch, as detailed below, and integrates all variants belonging to a single batch. A group may be a single sample; simply use the sample ID as the group ID.

## Input files
Variant calls must be standardized to the following specifications before integration. See the example preprocessing module for guidance.

* `input_vcfs/{source}.{group}.vcf.gz`  
    Tabix-indexed PE/SR VCFs per algorithm. 
    - {source} indicates the source algorithm.
    - {group} indicates a subgroup of samples which were called jointly.
    - VCF records are required to include INFO fields for SVTYPE, CHR2, END,
      STRANDS [++,+-,-+,--], SVLEN, and SOURCES.  Currently, DEL, DUP, INV, and
      BND are supported SVTYPEs; INS have not been tested. BND and INV
      breakpoints must be segregated and annotated with strand.  
      (NOTE: END has become a reserved attribute in pysam 0.11.2.1 and may be
      deprecated here in the future.)
* `input_beds/{batch}.{svtype}.bed.gz`  
    All per-sample depth calls in a batch, merged across algorithms.
    - Depth calls must be segregated by {svtype}, which may be DEL or DUP.
    - Each line corresponds to a single call in a single sample.
    - First six columns must be chrom, start, end, name, sample, svtype. Any
      following columns are discarded during integration.
    - In our preprocessing module, these files are generated by taking all
      algorithms's calls for a given sample and performing a bedtools merge,
      then concatenating and sorting all sample calls.

## Output files

* `vcfcluster/{batch}.{source}.{chrom}.vcf`  
    Clustered PE/SR variants, per batch, per source, and per chromosome.
* `rdtest_beds/{batch}.{source}.{chrom}.bed`  
    Clustered PE/SR variants in RdTest format. 

## Module configuration and input
The configuration file `config.yaml` outlines the module's inputs and parameters, and should be modified accordingly to each specific project.
All variables controlling pipeline operation can be modified in `config.yaml`.

* `batches` : filepath  
    Sample/group/batch key.

* `groups` : filepath  
    List of groups to include during integration. Expects one PE/SR VCF per
    group.

* `chroms`: filepath  
    List of chromosomes to include during integration. Integration is
    parallelized by chromosome.

* `pesr_sources` : list of strings  
    List of all PE/SR algorithms to merge. Expects one VCF from each algorithm
    for each group; integrating an algorithm from only a subset of groups is
    not yet supported.

* `cnv_types`: list of strings  
    List of SV classes to include during integration of depth variants.
    Mostly useful for testing. (Default: DEL,DUP)

* `vcfcluster` : list of params  
    vcfcluster parameters; see `svtools vcfcluster -h` for details

* `bedcluster` : list of params  
    bedcluster parameters; see `svtools bedcluster -h` for details


### Batches
The workflow requires a `batch` key, describing each sample in the cohort and the batch to which they belong. An example:
```
sample       group   batch
fam1.fa      fam1   Pilot
fam1.mo      fam1   Pilot
fam1.p1      fam1   Pilot
fam1.s1      fam1   Pilot
fam2.fa      fam2   Phase1
fam2.mo      fam2   Phase1
fam2.p1      fam2   Phase1
fam2.s1      fam2   Phase1
```
Note the `group` column. Each algorithm was run on some group of samples, which we are now trying to integrate. The `group` column indicates the ID used for each group in the original algorithm runs, and is used to identify the corresponding VCF for each sample.
The configuration variable `batches indicates the key to use.

### vcflists
For each algorithm to be processed, a `vcflist` describing location of the per-sample vcf should be prepared, names as `{batch}.{source}.list` and placed under `vcflist/`. Here's an example:
```
../00_preprocessing/filtered_vcfs/delly.sample1.vcf.gz
../00_preprocessing/filtered_vcfs/delly.sample2.vcf.gz
../00_preprocessing/filtered_vcfs/delly.sample3.vcf.gz
```

### PE/SR algorithms (VCFs)
Calls from PE/SR algorithms must be provided as standardized VCFs (see Module 0). The filepath to each individual VCF must be labeled with the file's source, i.e., the algorithm which produced it, and the group of samples included in the file. As example:
```
delly.11002.vcf.gz
delly.11006.vcf.gz
```
The workflow will search for these files in the specified `input_vcfs` directory.
```
input_vcfs: ../00_preprocessing/filtered_vcfs/
```

### Depth algorithms (BEDs)
Depth calls should be concatenated into one BED per batch and CNV type, with each entry corresponding to a call in a single sample (see Module 0 for details). The filepath to each individual BED must again be formatted accordingly, here with the `batch` of samples and the `svtype` included. As example:
```
Phase1.DEL.vcf.gz
```

The workflow will search for these files in the specified `input_beds` directory.
```
input_vcfs: ../00_preprocessing/std_beds/
```


## Manual process 

Follow these steps to manually cluster pair-end split read (pesr) calls:

1. Cluster all VCFs in a batch from a given algorithm
```
svtype vcfcluster vcflists/{batch}.{source}.list vcfcluster/{batch}.{source}.{chrom}.vcf -r {chrom}
bgzip vcfcluster/{batch}.{source}.{chrom}.vcf
tabix vcfcluster/{batch}.{source}.{chrom}.vcf.gz
```
2. Convert to RdTest format
```
python scripts/make_pesr_rdtest_bed.py vcfcluster/{batch}.{source}.{chrom}.vcf.gz rdtest_beds/{batch}.{source}.{chrom}.bed
```


Follow these steps to manually cluster depth calls:

1. Cluter CNV calls

```
svtools bedcluster ../00_preprocessing/std_beds/{batch}.{svtype}.bed.gz -r {chrom} -p {batch}_depth_{svtype}_{chrom} > bedcluster/{batch}.{svtype}.{chrom}.bed
```
2. Aggregate observations into variants and convert to RdTest format
```
cat \
  <(scripts/make_depth_rdtest_bed.py {batch}.DEL.{chrom}.bed} | sed '1d') \
  <(scripts/make_depth_rdtest_bed.py {batch}.DUP.{chrom}.bed} | sed '1d') \
  | sort -k1,1V -k2,2n \
  | cat <(echo -e "#chrom start end name samples svtype" | sed -e 's/ /\\t/g') - \
  > rdtest_beds/{batch}.depth.{chrom}.bed
```
3. Transform rdtest_beds to vcf
```
svtools rdtest2vcf rdtest_beds/{batch}.depth.{chrom}.bed ref/batches.list vcfcluster/{batch}.depth.{chrom}.vcf.gz
```


